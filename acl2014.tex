\documentclass[11pt]{article}
\usepackage{times}
\usepackage{latexsym}
\usepackage{url}
\usepackage{color}
\usepackage{graphicx}
\usepackage{cjhebrew}
\usepackage[T2A,OT2,OT1]{fontenc}
\usepackage{ucs}
\usepackage{CJKutf8}
\usepackage{footnote}

\usepackage[hebrew,english]{babel}
\newcommand{\heb}[1]{%
  \foreignlanguage{hebrew}{#1} }

\newcommand\cyr{%
\renewcommand\rmdefault{wncyr}%
\renewcommand\sfdefault{wncyss}%
\renewcommand\encodingdefault{OT2}%
\normalfont
\selectfont}
\DeclareTextFontCommand{\textcyr}{\cyr}
\usepackage{acl2014}

\newcommand{\ddcomment}[1]{\textcolor{red}{[$^{\textsc{D}}_{\textsc{D}}$ #1]}}
\newcommand{\spcomment}[1]{\textcolor{blue}{[$^{\textsc{S}}_{\textsc{P}}$ #1]}}
\newcommand{\jmcomment}[1]{\textcolor{magenta}{[$^{\textsc{J}}_{\textsc{M}}$ #1]}}
\newcommand{\eat}[1]{\ignorespaces}

\setlength\titlebox{6.5cm}    % Expanding the titlebox

\title{Enhanced Search with Wildcards and Morphological Inflections\\in the Google Books Ngram Viewer}

\eat{\author{Jason Mann, David Zhang, Lucille Yang, Slav Petrov and Dipanjan Das\\
	Google Inc. \\
	{\tt jcm2207@columbia.edu, dzhang21@gmail.com, ly77@cornell.edu}\\
	{\tt \{slav,dipanjand\}@google.com}}
}

\date{}

\begin{document}
\maketitle

\begin{abstract}

We present a new version of the Google Books Ngram Viewer, which plots
the frequency of words and phrases over the last five
centuries; its data encompasses 6\% of the world's published books.
The new Viewer adds three features for more powerful search: wildcards,
morphological inflections, and case insensitivity. These additions allow
the discovery of patterns that were previously difficult to find in the Google Books Ngram data,
and further facilitate the study of linguistic trends in printed text.

\end{abstract}

\section{Introduction}

The Google Books Ngram project facilitates the analysis of cultural, social and linguistic trends through five centuries of written text in eight languages. The Ngram Corpus \cite{culturomics,lin2012syntactic} consists of words and phrases (i.e., ngrams) and their usage frequency over time; it is freely available for download. The interactive Ngram Viewer\footnote{See \url{http://books.google.com/ngrams}.} allows users to retrieve and plot the frequency of multiple ngrams on a simple webpage. The Viewer is widely popular and can be used to efficiently explore and visualize patterns in the underlying ngram data. To cite a few examples, the ngrama data has been used to detect emotion trends in 20th century books \cite{acerbi.etal.2013}, to analyze text focusing on market capitalism throughout the past century \cite{Schulz2013}, detect social and cultural impact of personalities throughout history \cite{skiena.ward.2013}, or to analyze the correlation of economic crises with a literary `misery index' reflected in printed text during crises periods \cite{bentley.et.al.2014}.

One major limitation of the Ngram Viewer, however, is that all the reasoning needs to be carried out by the user, and that the Viewer cannot automatically discover interesting trends. For example, to compare the popularity of different presidents, one might search for `\texttt{President Kennedy, President Nixon, President Roosevelt}' etc. In order to determine the most popular president, one would need to search for all presidents! This is cumbersome and something that we want to do automatically.

In this paper we therefore present an updated version of the Viewer that enhances its search functionality. Traditional searches retrieve and plot the frequency of individual, user-specified ngrams. Instead, the three new features that we introduce expand the user query and automatically retrieve related nrgams in order facilitate the automatic discovery of patterns in the underlying data. First, users can replace one query term with a placeholder symbol `\texttt{*}' (wildcard, henceforth), which will return the ten most frequent expansions of the wildcard in the underlying corpus for the specified year range. 
%Figure~\ref{fig:examples}(a) shows the automatically discovered increase in references to the University of California. 
Second, by adding a specific marker to any word in a query (`\texttt{\_INF}'), ngrams with all morphological inflections of that word will be retrieved. 
%Figure~\ref{fig:examples}(b) shows the four inflected forms of the word book in the ngram `book a hotel'.
Finally, the new Viewer supports case-insensitive searches, which return all capitalization variants of the query ngram. Figure~\ref{fig:examples} provides examples for these three new types of queries.
%Figure~\ref{fig:examples}(c) shows the decline in the camel-case spelling of the surname Fitzgerald.
% Slav: we could discuss the examples in Fig. 1 here.

While it is fairly obvious how the above searches can be implemented via brute-force computation, supporting an interactive application with low latency necessitates some non-trivial engineering. In particular the wildcard search poses some challenges because the most frequent expansions depend on the selected year range (consider the frequency with which presidents are mentioned during different decades for example). To this end, we provide details on our system architecture in \S\ref{sec:overview}  and discuss how the new search features are implemented in \S\ref{sec:features}.
% We could add a sentence summarizing how we deal with wildcards here.

In addition, this demonstration presents an overhaul of the Viewer's user interface (\S\ref{sec:interface}), with interactive features that allow for easier management of the increase in data points returned. For example, to normalize for morphological inflections or casing, the frequencies of multiple ngrams can be aggregated via a (right) mouse-click. Additionally, lines can be highlighted or faded (via hovering or mouse-clicks) to focus on particular ngrams and make trends more apparent.


\begin{figure*}
\centering
\hspace*{-0.5cm}
\includegraphics[width=0.33\textwidth]{graphs/university}
\hspace*{0.1cm}
\includegraphics[width=0.33\textwidth]{graphs/book}
\hspace*{0.1cm}
\includegraphics[width=0.33\textwidth]{graphs/fitzgerald}
\hspace*{-0.5cm}
\vspace*{-0.25cm}\caption{\label{fig:examples}
Example queries highlighting the new functionality.\footnote{These figures show fewer results than returned by the Ngram Viewer due to space considerations.} Figures need to be updated. Just a placeholder for now.}
\end{figure*}


While an analysis and interpretation of trends uncovered with the new search interface is beyond the scope of this paper, we include some interesting use cases in \S\ref{sec:usecases}. Many of the presented queries were difficult (or even impossible) to execute in the previous versions of the Ngram Viewer. We hope the functionality of the Viewer will help uncover trends and patterns not readily apparent in the data.


\section{System Overview}
\label{sec:overview}

In this section we present an overview of the system architecture. We briefly review the underlying corpus and architecture of previous versions of the Viewer \cite{culturomics,lin2012syntactic} and then focus on the extensions added in this version. It should be emphasized that this demonstration updates only the Viewer, and provides tools for easier analysis of the underlying data. The ngram data itself is not updated and is identical to that of \newcite{lin2012syntactic}.


\subsection{Ngram Corpus}
	The Google Books Ngram Corpus\footnote{Downloadable from \texttt{https://books.google.com/} \texttt{ngrams/datasets}.} provides ngram counts for eight different languages over more than 500 years; additionally, the English corpus is split further into British vs. American English and Fiction to aid domain restriction. This corpus is a subset of all the books digitized at Google, and represents more than 6\% of all publicized texts in its newest edition \cite{lin2012syntactic}. The differences between the first and second versions of the corpus are discussed at length in the aforementioned paper.
	

Sentences from the Google Books Corpus are tokenized and segmented based on manually devised rules\footnote{Excluding Chinese, where a statistical segmentation system is used} that also capture those that span across page boundaries. \textsf{\textsc{\_start\_}} and \textsf{\textsc{\_end\_}} designate beginning and end tokens for distinguishing sentence medial ngrams from those near sentence boundaries \cite{lin2012syntactic}.

The current version of the corpus is tagged using the universal part-of-speech tag set containing twelve coarse categories, as described by \newcite{petrov2012universal}. Individual words exist in both tagged and untagged forms for all ngrams up to a length of three, including dependency relations. The dependency ngrams are created according to \newcite{lin2012syntactic} and specify pairwise syntactic relationships between words in the same sentence. These relationships are shown by directed arcs that specify a single head word for each sentence. Also, in raw ngrams of up to length three, POS tags can stand in place of a word to represent the sum of all the ngram counts for that specific tag. When combined with the tools we describe below, these tags provide a further layer of abstraction in a query.



\subsection{Architecture}
The Viewer provides a lightweight interface to the underlying ngram corpora. In its basic form, user requests are directed through the server to a simple lookup table containing the raw ngrams and their frequencies. This data flow is displayed in the top part of Figure \ref{fig:architecture} and is maintained for queries containing none of the tools offered by the update.

The new types of queries could be in principle be implemented by scanning the raw ngrams on the fly and returning the relevant subset. Given the large quantity of ngrams, such an approach would be computationally very expensive and too slow for an interactive application. We therefore pre-compute intermediate results that can be used to more efficiently retrieve the results for the new queries. The intermediate results are stored in additional lookup tables (shown at the bottom in Figure \ref{fig:architecture}) that are queried first and then trigger potentially multiple requests to the raw ngram tables. For example, the intermediate results table for the morphological variants search contains inflected forms for all unigrams. These inflected forms are substituted for the selected query term and the resulting ngram is looked up in the raw ngram table. We describe the intermediate results tables and how they are generated in the next section.

It should be noted that we only support one expansion per query ngram. This is needed in order to avoid the combinatorial explosion that would result from mixing multiple expansions in the same ngram.



\begin{figure}
\includegraphics[width=20em,keepaspectratio=true]{system_architecture}
\caption{\label{fig:architecture}Diagram of new system architecture.}
\end{figure}


\section{New Features}
\label{sec:features}
Here, we describe the novel aspects of the Ngram Viewer introduced in this demonstration paper.
\begin{table*}
\small
\centering
\begin{tabular}{|c|c|}
\hline
\textbf{Query}	& \textbf{Possible Replacements}	\\ \hline
a * man					& a young man, a good man, a kind man, a wild man		\\ \hline
booked\texttt{=>}*\_NOUN	& \begin{tabular}[c]{@{}c@{}}booked\texttt{=>}flight\_NOUN, booked\texttt{=>}passage\_NOUN,
						\\ booked\texttt{=>}room\_NOUN, booked\texttt{=>}eat\_NOUN\end{tabular} \\ \hline
John said\_INF			& John says, John said, John say, John saying                                                                                                                                   \\ \hline
book\_INF\_NOUN			& book, books                                                                                                                                                                   \\ \hline
\begin{tabular}[c]{@{}c@{}}the cook\\ (case insensitive)\end{tabular} & THE COOK, the cook, The Cook, the Cook, The cook                                                                                                                              \\ \hline
\end{tabular}
\caption{\label{tab:wildcard}
Examples of precompiled wildcard, inflection, and case insensitive queries.}
\end{table*}


\subsection{Wildcards}
\label{sec:wildcards}
	We support the use of wildcards by utilizing an additional database that stores the most frequent expansions of queries to the ngram corpus. This wildcard database is created as a pre-compilation step when creating the Ngram Corpus from the Google Books data. When a new ngram is created, one word or tag at a time is replaced with the wildcard symbol, `*', creating a wildcard query. The query becomes a key in a string indexed lookup table, and the original ngram is added to a list of ngrams which are its values. As mentioned above, due to space considerations we were not able to store all possible expansions for every wildcard ngram we precomputed. Also, we could not precompute a perfect set of the top 10 ngrams for every possible year range, while this would require intermediate storage space on the order discussed above, as well as the computation time to calculate the top 10 for $\frac{n(n+1)}{2}$ time periods for each wildcard. Instead we estimate the top 10 during the creation of wildcard ngrams, by limiting the number of expansions to the top ten for every year. We gather these top 10 lists into a union and map the raw ngrams to the wildcard ngram string in our table. 
	
	During this process, we filter punctuation from consideration as a valid expansion because in practice punctuation returns uninteresting results. On this note, it may be useful to specify a specific POS tag (i.e. `*\textsf{\textsc{\_noun}}') to provide more specific results. At runtime, union of expansion ngrams is processed for the specific year range requested and the top ten results are returned. For examples of expansions see Table \ref{tab:wildcard}. 


\subsection{Morphological Inflections}
Inflections of words in search queries are handled using a Google Search interface that can provide morphological variations of words for different syntactic categories \cite{durrett2013supervised}. As this type of request utilizes an internal API, the results from a specific request are subject to change. Unlike wildcard substitutions, there is no need for pre-computation; given a query with the keyword \textsf{\textsc{\_inf}} attached to a word (e.g., `John said\textsf{\textsc{\_inf}}'), we get the counts of all the ngrams that start with `John' and have the morphological inflections of the root form `say' as its second word in the Ngram Corpus. We have noticed that there can be more than 10 results returned per query, especially for morphologically rich languages like Russian, unlike the wildcard search feature. Therefore we have updated the user interface to better deal with more data lines (\S\ref{sec:interface}). We do not allow the combination of morphological inflections with wildcards and/or case insensitive searches
because it slows down the retrieval process.

\subsection{Case Insensitive}
Case insensitive searches are enabled by selecting a check box on the new interface. These queries, like the wildcards, are referenced to a separate database that contains a mapping of different case combinations to the ngram string in lowercase. The possible combinations of case are: ALL CAPS, first letter Capitalization (all possible variations), and all lower case. During experimentation, we noticed that often there are many case variants of a given query for which the ngram counts are negligible; hence, to keep our retrieved results meaningful, we filter out all case variants that have a cumulative count of less than 1\% of the most frequent case variant for a given year range.



\section{User Interface}
\label{sec:interface}
Due to the increased number of results returned per query, we have also updated the user interface. Interactive functionality allows the user to highlight a line by hovering over it, keep that focus by left clicking, and clear all focused lines by double clicking. For any of the three queries mentioned above, you may also right click on any of the queries returned to combine them into the total line for the wildcard query. Another feature added to the interface is static URLs which maintain all of the raw ngrams retrieved from any query. This is to prevent statically linked charts from changing over time, and allowing for backwards compatibility.


\begin{figure*}
\includegraphics[width=.46\textwidth]{graphs/president*_all}
\includegraphics[width=.54\textwidth]{graphs/President*1950}
\includegraphics[width=\textwidth]{graphs/President*1800}
\caption{\label{fig:president} Comparison of specification of POS tag in wildcard search}
\end{figure*}
\section{Use Cases}
\label{sec:usecases}
The previous version of the Ngram Viewer brought the power of syntactic annotations and dependencies to the Ngram Corpus \cite{lin2012syntactic}, allowing for greater specificity when searching the corpus. The features we have added above continue this trend of specialization, but also provide the ability to group similar searches, preventing the need for overly verbose queries. Below we examine example uses of the new features independently and combined with those already present. We show specific queries here to highlight specific usages that we feel users will find the most beneficial, but wish to leave the analysis of the results to the experts.

The wildcard feature used on its own can be a powerful tool for the analysis of top expansions for a certain context. While powerful, we have found greater functionality from wildcards by their specification with POS tags. The user can attach an underscore and POS tag to either a wildcard-based or inflection based query to specify that the expansions returned should be a specific part of speech. Compare the utility of the generic wildcard and a search with a noun part-of-speech specification in a query examining president names, `President *'/`President *\textsf{\textsc{\_NOUN}}' shown in Figure \ref{fig:president}. The former gives a mixture of prepositions, particles, and verbs along with names of presidents, and because the latter specifies nouns the top expansions turn out to be names and more in line with the intention of the search. Also, note in Figure \ref{fig:president} the difference in expansions that searching over two different time ranges provides.




\jmcomment{Most popular words for context across year ranges or languages}
\begin{figure*}
\centering
\includegraphics[width=.48\textwidth]{graphs/apple}
\caption{\label{fig:apple} Discovery of Capitalization usage}
\end{figure*}
\begin{figure*}
\includegraphics[width=.48\textwidth]{graphs/light_INF}
\includegraphics[width=.48\textwidth]{graphs/light_INF_VERB}
\caption{\label{fig:light} Comparison of specification of POS tag in wildcard search}
\end{figure*}
\eat{\includegraphics[width=.48\textwidth]{graphs/drink}
\includegraphics[width=.48\textwidth]{graphs/drink_GER}
\includegraphics[width=.48\textwidth]{graphs/drink_UK}
\includegraphics[width=.48\textwidth]{graphs/drink_CHI}
\includegraphics[width=.48\textwidth]{graphs/drink_USA}
\includegraphics[width=.48\textwidth]{graphs/drink_FRE}
\includegraphics[width=.48\textwidth]{graphs/drink_HEB}
\includegraphics[width=.48\textwidth]{graphs/drink_ITA}
\includegraphics[width=.48\textwidth]{graphs/drink_RUS}
\includegraphics[width=.48\textwidth]{graphs/drink_SPA}}

\begin{savenotes}
\begin{table*}
\small
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
\hline
\begin{tabular}[c]{@{}c@{}}English \\ (All) \end{tabular}
&  \begin{tabular}[c]{@{}c@{}}American \\English\end{tabular} 
&  \begin{tabular}[c]{@{}c@{}}British \\English\end{tabular}
& German
& French
& Russian
& Italian                                                                                                                                     
& \begin{tabular}[c]{@{}c@{}}Chinese \\ (Simplified)\end{tabular}                                        
& Spanish                                                                                                                            
& Hebrew \\ \hline \hline
\begin{tabular}[c]{@{}c@{}}water\\ wine\\ blood\\ tea\\ cup 	\eat{\\ health\\ glass\\ beer\\ milk\\ coffee} \end{tabular} & 
\begin{tabular}[c]{@{}c@{}}wine\\ water\\ cup\\ blood\\ tea 	\eat{\\ health\\ glass\\ beer\\ coffee\\ milk}	\end{tabular} & 
\begin{tabular}[c]{@{}c@{}}wine\\ water\\ health\\ tea\\ blood	\eat{\\ cup\\ glass\\ beer\\ waters\\ milk}		\end{tabular} & 
\begin{tabular}[c]{@{}c@{}}Wein \\ Glas \\ Wasser \\ Kaffee \\ Bier	\eat{ \\ Komm \\ Trink \\ Schluck \\ Milch \\ Schnaps}	\end{tabular} &
\begin{tabular}[c]{@{}c@{}}vin \\ verre \\ au \\ sang \\ lait	\eat{ \\ coup \\ caf\'e \\ h\'e \\ calice \\ aux}	\end{tabular} & 
\begin{tabular}[c]{@{}c@{}} \textcyr{cha{\u i}} \\  \textcyr{vodu} \\  \textcyr{vino} \\  \textcyr{ego} \\  \textcyr{vodku}	
	\eat{ \\  \textcyr{kofe} \\  \textcyr{vina} \\  \textcyr{vody} \\ \textcyr{chashu} \\  \textcyr{emu}}	\end{tabular} & 
\begin{tabular}[c]{@{}c@{}}vino \\ acqua \\ icchiere \\ sangue \\ caff\'e	\eat{ \\ calice \\ acque \\ latte \\ irra \\ cicuta}	\end{tabular} & 
\begin{CJK}{UTF8}{gbsn} \begin{tabular}[c]{@{}c@{}} 酒 \\  茶 \\  水 \\  咖啡 \\  人	\eat{ \\  别人 \\  啤酒 \\  女儿 \\  烟 \\  们 }	 \end{tabular} \end{CJK}& 
\begin{tabular}[c]{@{}c@{}}agua \\ vino \\ \'a \\ sangre \\ aguas	\eat{ \\ vaso \\ cicuta \\ mas \\ leche \\ copa}	\end{tabular} & 
\begin{tabular}[c]{@{}c@{}}\heb{יין}\\ \heb{מים} \\ \heb{כוס}\\ \heb{ה} \\ \heb{תה}	\eat{\\ \heb{קפה} \\ \heb{כוסות} \\ \heb{שכר} \\ \heb{מיס}\\ \heb{חלב}}	\end{tabular} \\ \hline
\end{tabular}
\caption{\label{tab:drink} Comparison of top dependencies from 'drink' in all corpora\footnote{Queries were initiated by translation from 'drink' using Google Translate \jmcomment{is there a reference we should cite here for google translate?}}}
\end{table*}
\end{savenotes}

\jmcomment{Automatic viewing of irregular vs regular verbs}




\section{Conclusions}
We have presented a new version of the Ngram Viewer with some new functionality. With the introduction of these new features, users can perform more powerful searches that show trends which were not possible to extract from earlier versions of the tool. The new features have been highlighted in a recent article by the Atlantic, as well on various blogs.

\jmcomment{We can cite examples from the media where this has been mentioned, and also show examples from several blog posts/entries from the internet:
http://sciencerefinery.com/2013/10/28/google-ngram-viewer-now-more-powerful-than-ever/
http://www.devingriffiths.com/google-books/google-n-gram-studies/
http://languagelog.ldc.upenn.edu/nll/?p=8472
http://www.textualscholarship.nl/?p=14051}

\bibliographystyle{acl}
\bibliography{acl2014}
\end{document}
